{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    sys.path.append(os.path.join(os.environ['SUMO_HOME'], 'tools'))\n",
    "import sumolib\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Add the \"scripts\" directory to sys.path\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "scripts_dir = os.path.abspath(os.path.join(current_dir, 'scripts'))\n",
    "sys.path.append(scripts_dir)\n",
    "import vehParameters\n",
    "import osmAPI as osm\n",
    "import LLAMAconnect\n",
    "\n",
    "FOLDER_NAME = \"ufscar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining paths and setting up osm.sumocfg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_xml_child(file_path, parent_tag, child_tag, child_value):\n",
    "    \"\"\"\n",
    "    Adds a new child parameter inside a specified parent tag in the XML configuration file.\n",
    "    If the parent tag does not exist, it creates a new parent tag (<parameter>) with the child.\n",
    "    It also checks if the child element already exists to prevent duplicates.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the XML configuration file.\n",
    "        parent_tag (str): The parent tag under which to add the child (e.g., 'input').\n",
    "        child_tag (str): The child tag to add (e.g., 'additional-files').\n",
    "        child_value (str): The value to set for the new child tag.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the addition was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Find the parent element by tag\n",
    "        parent_elem = root.find(parent_tag)\n",
    "        if parent_elem is None:\n",
    "            print(f\"Parent tag '{parent_tag}' not found. Creating new parent tag.\")\n",
    "            parent_elem = ET.Element(parent_tag)\n",
    "            root.append(parent_elem)\n",
    "            print(f\"Created new parent tag <{parent_tag}>.\")\n",
    "\n",
    "        # Check if the child element already exists inside the parent element\n",
    "        existing_child = parent_elem.find(child_tag)\n",
    "        if existing_child is not None: \n",
    "            \n",
    "            if existing_child.get('value') == child_value:\n",
    "                print(f\"Child <{child_tag}> with value '{child_value}' already exists. Skipping addition.\")\n",
    "                return False\n",
    "            else:\n",
    "                print(f\"Child <{child_tag}> already exists. Updating value to '{child_value}'.\")\n",
    "                existing_child.set('value', child_value)\n",
    "                tree.write(file_path, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "                print(\"XML file updated successfully.\")\n",
    "                return True\n",
    "\n",
    "        # Create the new child element and set its value\n",
    "        new_child = ET.Element(child_tag)\n",
    "        new_child.set('value', child_value)\n",
    "        print(f\"Created <{child_tag}> with value '{child_value}'.\")\n",
    "\n",
    "        # Add the new child to the parent element\n",
    "        parent_elem.append(new_child)\n",
    "        print(f\"Added <{child_tag}> to <{parent_tag}>.\")\n",
    "\n",
    "        # Write the updated XML to the file\n",
    "        tree.write(file_path, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "        print(\"XML file updated successfully.\")\n",
    "        return True\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"XML Parsing error: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET_PATH = f'{FOLDER_NAME}/osm.net.xml'\n",
    "ADDITONALS_PATH = f'{FOLDER_NAME}/park.add.xml'\n",
    "SUMOCFG_PATH = f'{FOLDER_NAME}/osm.sumocfg'\n",
    "PA_REROUTER_PATH = f'{FOLDER_NAME}/pa_rerouter.xml'\n",
    "\n",
    "# Setting up additional files\n",
    "add_xml_child(SUMOCFG_PATH, 'input', 'additional-files', \"park.add.xml, pa_rerouter.xml\")\n",
    "\n",
    "# Setting up time to teleport as -1 (never teleport)\n",
    "add_xml_child(SUMOCFG_PATH, 'processing', 'time-to-teleport', '-1')\n",
    "\n",
    "# Adding lateral resolution to use SubLane model\n",
    "add_xml_child(SUMOCFG_PATH, 'parameters', 'lateral-resolution', '0.8')\n",
    "\n",
    "net = sumolib.net.readNet(NET_PATH)\n",
    "parkingAreas = list(sumolib.output.parse(ADDITONALS_PATH, \"parkingArea\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_print():\n",
    "    sys.stdout.write(\"\\r\")  # Move the cursor to the beginning of the line\n",
    "    sys.stdout.write(\" \" * 50)  # Overwrite with spaces to clear the line\n",
    "    sys.stdout.write(\"\\r\")  # Move back to the beginning again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_parking_spot(lanes, parkingAreas):\n",
    "    # Example of parkingArea:\n",
    "    # <parkingArea id=\"pa-1046248579#0\" lane=\"-1046248579#0_0\" roadsideCapacity=\"94\" length=\"5.00\"/>\n",
    "    # Returns parkingArea id if there is a parking spot in the lane\n",
    "    lane_ids = [lane.getID() for lane in lanes]\n",
    "    for park in parkingAreas:\n",
    "        if park.lane in lane_ids:\n",
    "            return park.id\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClosestEdges(lat, lon, radius, maxEdges=10):\n",
    "    # Gets the 10 closest edges to the given lat, lon\n",
    "    x, y = net.convertLonLat2XY(lon, lat)\n",
    "    edges = net.getNeighboringEdges(x, y, radius)\n",
    "    closestEdges = []\n",
    "    if (len(edges) > 0):\n",
    "        distanceAndEdges = sorted([(dist, edge) for edge, dist in edges], key=lambda x:x[0])\n",
    "\n",
    "        ## Checking if the edge found can be used by passenger car\n",
    "        for dist, edge in distanceAndEdges:\n",
    "            if edge.allows('passenger'):\n",
    "                closestEdges.append(edge)\n",
    "\n",
    "    if len(edges) == 0:\n",
    "        print(f'No edges found for {lat}, {lon}. Perhaps location is not inside the network or there are no viable roads inside the radius.')\n",
    "        return None\n",
    "    \n",
    "    return closestEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParkingSpot(lat, lon, radius, parkingAreas):\n",
    "    # Get the parking spot closest to the given lat, lon\n",
    "    # Used to set stops for the vehicles\n",
    "\n",
    "    edges = getClosestEdges(lat, lon, radius)\n",
    "    # Look for parking spots\n",
    "    for i in range(len(edges)):\n",
    "        parking_spot = has_parking_spot(edges[i].getLanes(), parkingAreas)\n",
    "        if parking_spot:\n",
    "            return parking_spot\n",
    "    print(f\"No parking spot found close to {lat}, {lon}. Perhaps decrease the radius?\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPath(location_time_list, parkingAreas, steps_per_stop = 10):\n",
    "    # All that is needed to create the trip are the stops (parking areas) and the start and end edges.\n",
    "    # The duarouter is responsible for finding the path between the edges going through the stops.\n",
    "    # Here, we get the edges and stops that are going to be sent to LLAMA to create the trip.\n",
    "\n",
    "    # 'coordinates' is a list of tuples with the latitude and longitude of the points of interest, for example IC, FEEC, IC means that\n",
    "    # the vehicle will start from IC, stop at a parking lot close to FEEC, and then back to IC.\n",
    "    # The first and last coordinates should be edges and the others should be parking spots.\n",
    "    # `steps_per_stop` is the number of simulation steps that the vehicle will stay at each stop.\n",
    "\n",
    "    # Departure for 7 is 0, 8 is 100, 9 is 200 and so on\n",
    "    stop_durations = []\n",
    "    departures = list(location_time_list.keys())\n",
    "    stop_durations.append(-1) # Indicates this is an edge and not a parking spot\n",
    "\n",
    "    path = []\n",
    "    locations = list(location_time_list.values())\n",
    "    home = getClosestEdges(*locations[0], radius)[0].getID()\n",
    "    path.append(home)\n",
    "    \n",
    "    for i in range(1, len(locations)-1):\n",
    "        stop_durations.append(steps_per_stop * (departures[i] - departures[i - 1]))\n",
    "        ps = getParkingSpot(*locations[i], radius, parkingAreas)\n",
    "        if ps is not None:\n",
    "            path.append(ps)\n",
    "        else:\n",
    "            print(f\"Could not find parking spot for {locations[i]}\")\n",
    "            raise Exception(f\"Could not find parking spot for {locations[i]}\")\n",
    "\n",
    "    path.append(home)\n",
    "    stop_durations.append(-1)\n",
    "    \n",
    "    return path, stop_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathToXML(path, vehicleID, veh_type, departure_time, stop_durations):\n",
    "    # Converts the path to the XML format that LLAMA understands\n",
    "    xml = f'<trip id=\"{vehicleID}\" type=\"{veh_type}\" depart=\"{departure_time}\" from=\"{path[0]}\" to=\"{path[-1]}\">\\n'\n",
    "    for i in range(1, len(path)-1):\n",
    "        xml += f'\\t<stop parkingArea=\"{path[i]}\" duration=\"{stop_durations[i]}\"/>\\n'\n",
    "    xml += '</trip>'\n",
    "    return xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(institutes):\n",
    "    cleaned_institutes = []\n",
    "    for institute in institutes:\n",
    "        # Remove parenthesis and everything after it\n",
    "        institute = re.sub(r'\\(.*', '', institute).strip()\n",
    "        \n",
    "        # Split by hyphen and take the longest slice\n",
    "        parts = institute.split('-')\n",
    "        longest_part = max(parts, key=len).strip()\n",
    "        # Split by '/' and add both parts to the cleaned_institutes list\n",
    "        if '/' in longest_part:\n",
    "            parts = longest_part.split('/')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                if part not in cleaned_institutes:\n",
    "                    cleaned_institutes.append(part)\n",
    "        else:\n",
    "            if longest_part not in cleaned_institutes:\n",
    "                cleaned_institutes.append(longest_part)\n",
    "        \n",
    "    return cleaned_institutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering important places in the university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: You can try to automatically get the Institutes and Colleges from the OSM API, but this is not guaranteed to work. Sometimes buildings are not tagged and sometimes their names are not what you expect.\n",
    "importlib.reload(osm)\n",
    "uni_center_lat, uni_center_lon = -21.983874743373647, -47.8815156521976\n",
    "uni_radius = 10000\n",
    "filters = ['Instituto', 'Faculdade', 'Departamento'] # Only buildings with these words in the name will be considered (use this wisely to get the desired buildings, because the API retrieves all buildings that are marked as colleges or university buildings)\n",
    "\n",
    "resp = osm.find_nearby_university_buildings(uni_center_lat, uni_center_lon, uni_radius, filters)\n",
    "institutes = [i['name'] for i in resp]\n",
    "\n",
    "print(len(institutes), institutes)\n",
    "institutes = clean_response(institutes) # Clean the names of the institutes, removing any acronyms or parenthesis that may be present\n",
    "print(len(institutes), institutes) # Sometimes the API returns the same building with different names, so this is a way to reduce the number of duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating routines via LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important not to use short names of institutes, like IB for institute of biology, because the LLM will not be able to assign the students to the correct institute.\n",
    "places ={\n",
    "    'leisure': [\"bar\", \"mall\", \"library\", \"park\", \"garden\"],\n",
    "    'eating': [\"restaurant\", \"cafe\"],\n",
    "    'shopping': [\"clothes\", \"mall\", \"supermarket\", \"department_store\", \"fuel\"],\n",
    "    'sports': [\"fitness_centre\"],\n",
    "    'institute': institutes, # Here, you could use the places found above or manually add the names of the institutes/colleges/faculties\n",
    "    'university': [\"University of Campinas\"],\n",
    "}\n",
    "\n",
    "student_info = \"O estudante é um estudante de ciências ambientais.\"\n",
    "importlib.reload(LLAMAconnect)\n",
    "number_of_trips = 4\n",
    "responses = LLAMAconnect.generate_response_trips(student_info, places, number_of_trips) # number of trips defaults to 5\n",
    "for i in range(3):\n",
    "    pprint(json.loads(responses[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The getHome function must be set to the desired student home location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OSM API to get coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHome():\n",
    "    # Should be a random value considering where students live\n",
    "    return (-21.993529, -47.887696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoords(trip, sulfixo, institutes, start_radius, step_radius, limit_radius, n_options = 3):\n",
    "    # Returns a dictionary with the latitude and longitude of the locations of interest\n",
    "    # The suffix is the name of the state, city and neighborhood that will be added to the end of each location to improve the search\n",
    "    # 'start_radius' is the initial radius of the search, 'step_radius' is the amount that will be added to the radius if the location is not found and 'limit_radius' is the maximum radius that will be used. After that, the student will choose not to leave the place he is at.\n",
    "    # 'n_options' is the number of options of places we ideally want to find to choose from. This only applies while the limit_radius is not exceeded\n",
    "    \n",
    "    coords = {} # Coordinates for every place the student will visit\n",
    "    ignore = {} # Stores combinations that have already been tested, for example, if library to mall was tested before and was\n",
    "    importlib.reload(osm)\n",
    "    for i in range(len(trip)):\n",
    "        local = trip[f'{i + 7}']['location']\n",
    "        local_comp = local + \", \" + sulfixo\n",
    "\n",
    "        if local in coords.keys():\n",
    "            continue\n",
    "        \n",
    "        if local == 'home':\n",
    "            coords['home'] = getHome()\n",
    "            continue\n",
    "        \n",
    "        elif local in institutes:\n",
    "                result = osm.geocode_address(local_comp)\n",
    "                \n",
    "                if not result:\n",
    "                    raise Exception(f\"Could not get coordinates for {local}, maybe its name is not correct\")\n",
    "\n",
    "                lat, lon = result[0]['latitude'], result[0]['longitude']\n",
    "                print(f\"\\033[1mFound {local} at {lat}, {lon}.\\033[0m\")\n",
    "        else:\n",
    "            found = False\n",
    "            print(f\"Looking for {local}...\", end='', flush=True)\n",
    "\n",
    "            # Storing the previous location to use as a reference for the next search\n",
    "            previous = coords[trip[f'{i + 6}']['location']]\n",
    "            result = osm.find_nearby_building(previous[0], previous[1], local, radius=start_radius)\n",
    "            expanded = start_radius\n",
    "            if len(result) > 0:\n",
    "                found = True\n",
    "\n",
    "            # If the location is not found or there are less optios than expected, expand the search radius\n",
    "            while len(result) == 0 or len(result) < n_options:\n",
    "                expanded += step_radius\n",
    "\n",
    "                if expanded > limit_radius:\n",
    "                    break\n",
    "\n",
    "                result = osm.find_nearby_building(previous[0], previous[1], local, radius=expanded)\n",
    "                if found == False and (len(result) > 0):\n",
    "                    found = True # Found at least one option, but will keep looking for more until the limit is reached\n",
    "\n",
    "            if found == False:\n",
    "                result = [{'latitude': previous[0], 'longitude': previous[1]}]\n",
    "                flush_print()\n",
    "                print(f\"Could not find {local} in a radius of {limit_radius} meters. The student will not leave the place he is currently at.\")\n",
    "            else:\n",
    "                random.shuffle(result) # Randomize the results to avoid always getting the absolute closest building\n",
    "                lat, lon = result[0]['latitude'], result[0]['longitude']\n",
    "                flush_print()\n",
    "                print(f\"Found {len(result)} options for {local}: {[x['name'] for x in result]}\")\n",
    "                print(f\"\\033[1m{local} picked: {result[0]['name']} at {lat}, {lon}.\\033[0m\")\n",
    "\n",
    "        \n",
    "        coords[f'{local}'] = (lat, lon)\n",
    "        \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordsToTrip(trip, coords):\n",
    "    location_time = {}\n",
    "    home = coords['home'] # Gets a random home location for each student\n",
    "    last = home\n",
    "    location_time[7] = last\n",
    "    \n",
    "    for j in range(1, len(trip)):\n",
    "        local_coords = coords[trip[f'{j + 7}']['location']]\n",
    "        if local_coords != last:\n",
    "            location_time[j + 7] = local_coords\n",
    "            last = local_coords\n",
    "\n",
    "    return location_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sufixo = \"Sao Carlos, SP, Brazil\"\n",
    "trips = {}\n",
    "location_time_list = []\n",
    "radius = 200\n",
    "for i in range(len(responses)):\n",
    "    json_response = json.loads(responses[i])\n",
    "    trips[i] = json_response\n",
    "    print(f\"Getting coords for trip {i + 1}:\")\n",
    "    coords = getCoords(trips[i], sufixo, places['institute'], start_radius=500, step_radius=200, limit_radius=1500)\n",
    "    location_time_list.append(coordsToTrip(trips[i], coords))\n",
    "    print(\"\")\n",
    "print(\"All trips have been successfully generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Trips and Driving Styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomtrips_path = \"/usr/share/sumo/tools/randomTrips.py\"\n",
    "def randomtrips_getArgs(net_path, additional_path, v_class, n_trips):\n",
    "    args = [\n",
    "        \"-n\", net_path,\n",
    "        \"-o\", f\"{FOLDER_NAME}/randtrips.trips.xml\",\n",
    "        \"-r\", f\"{FOLDER_NAME}/randtrips.rou.xml\",\n",
    "        \"--additional\", additional_path,\n",
    "        \"--vclass\", v_class,\n",
    "        \"--vehicle-class\", v_class,\n",
    "        \"-e\", str(n_trips),\n",
    "        \"--validate\"\n",
    "    ]\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomTrips(net_path, add_path, vclass, n_trips):\n",
    "    # Run the randomTrips.py to create the trips\n",
    "    subprocess.run(['python3', randomtrips_path] + randomtrips_getArgs(net_path, add_path, vclass, n_trips), check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTripXML(param_dict, location_time_list, parkingAreas, departure_times, styles, veh_types_per_student, n_vtypes, steps_per_stop = 10, rand_trips=None, out_file_name='finaltrips.rou.xml'):\n",
    "    # Creates the XML for the trips\n",
    "    # 'departure_times' is a list with the departure times for each trip\n",
    "    # 'styles' is a list with the styles of the vehicles. The current supported styles are \"agg\" for aggressive and \"norm\" for normal\n",
    "    # 'veh_types_per_student' is a list with the vehicle types for each student\n",
    "    # 'n_vtypes' is the number of vTypes created for each style\n",
    "    # 'rand_trips' is a file containing the random trips\n",
    "    \n",
    "    importlib.reload(vehParameters)\n",
    "\n",
    "    xml = '<routes xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"http://sumo.dlr.de/xsd/routes_file.xsd\">\\n'\n",
    "\n",
    "    xml += '\\n<!-- BEGIN - LLM Generated trips -->\\n'\n",
    "\n",
    "    xml += '\\n<!-- Vehicles -->\\n'\n",
    "    vehdists = vehParameters.generateVehicleTypesLLM(param_dict, styles, n_vtypes)\n",
    "    xml += vehParameters.parseVehiclesXML(vehdists, styles, FOLDER_NAME)\n",
    "\n",
    "    xml += '\\n'\n",
    "    xml += '<!-- Trips -->\\n'\n",
    "    for i in range(len(location_time_list)):\n",
    "        path, stop_durations = getPath(location_time_list[i], parkingAreas, steps_per_stop=steps_per_stop)\n",
    "        xml += pathToXML(path, f'veh{i + 1}', veh_types_per_student[i], departure_times[i], stop_durations) + '\\n'\n",
    "\n",
    "    xml += '\\n\\n <!-- END - LLM Generated trips -->\\n\\n'\n",
    "\n",
    "    xml += '<!-- BEGIN - Random Trips -->\\n\\n'\n",
    "\n",
    "    if rand_trips:\n",
    "        start_read = False\n",
    "        with open(rand_trips, 'r') as f:\n",
    "            for line in f:\n",
    "                test = line.strip()\n",
    "                if test.startswith('<vType'):\n",
    "                    start_read = True\n",
    "                if start_read:\n",
    "                    if line.startswith('</routes>'):\n",
    "                        break\n",
    "                    xml += line\n",
    "\n",
    "    xml += '\\n</routes>'\n",
    "    \n",
    "    with open(f'{FOLDER_NAME}/{out_file_name}', 'w') as f:\n",
    "        f.write(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_str(data):\n",
    "    # Returns a string with the parameters and their descriptions to be used with the LLM\n",
    "    s = ''\n",
    "    for i in range(len(data)):\n",
    "        s += f\"Parameter: {data['Parameter'][i]}; Range: {data['Range'][i]}; Description: {data['Description'][i]}.\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "departure_times = []\n",
    "for i in range(len(location_time_list)):\n",
    "    departure_times.append((list(location_time_list[i].keys())[0] - 7) * 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting intervals for the parameters of different driving styles using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range_parameters(data, params, styles):\n",
    "    # Shell function to get the range parameters for the vehicles\n",
    "\n",
    "    importlib.reload(LLAMAconnect)\n",
    "    veh_parameters = LLAMAconnect.generate_range_parameters(params, styles) # Generates the parameters for the vehicles\n",
    "    param_dict = json.loads(veh_parameters)\n",
    "    missing_params = [param for param in data['Parameter'] if param not in list(param_dict.keys())]\n",
    "\n",
    "    while missing_params:\n",
    "        print(f\"Missing parameters in param_dict: {missing_params}. Trying new response.\")\n",
    "        veh_parameters = LLAMAconnect.generate_range_parameters(params, styles) # Generates the parameters for the vehicles\n",
    "        param_dict = json.loads(veh_parameters)\n",
    "        missing_params = [param for param in data['Parameter'] if param not in list(param_dict.keys())]\n",
    "\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_parameters(parameters_dict, styles):\n",
    "    # Sometimes it is necessary to check whether or not the answer will work in sumo because of some restrictions between parameters\n",
    "    # This changes the parameters_dict to make sure the parameters are OK\n",
    "\n",
    "    # Ensure maxSpeed accommodates the maximum speed implied by the distribution:\n",
    "    # max speed from distribution = speedFactor × default speed + 3 × deviation\n",
    "    default_maxspeed = 50\n",
    "    values_speed = parameters_dict['maxSpeed']\n",
    "    values_speedfactor = parameters_dict['speedFactor']\n",
    "\n",
    "    for style in styles:\n",
    "        speed = values_speed[f'{style}']['max']\n",
    "        speedfactor = values_speedfactor[f'{style}']['max']\n",
    "        min_maxspeed = speedfactor * default_maxspeed + 3 * 0.1 * default_maxspeed\n",
    "\n",
    "        if speed < min_maxspeed:\n",
    "            parameters_dict['maxSpeed'][f'{style}'] = min_maxspeed\n",
    "            print(f\"Changed maxSpeed of {style} driver from {speed} to {min_maxspeed}\")\n",
    "\n",
    "    print(\"Verification complete!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = [\"aggressive\", \"normal\", \"cautious\", \"super_aggressive\"] # Description of the styles of the vehicles that are going to be generated\n",
    "data = pd.read_csv('DBP.csv')\n",
    "params = csv_str(data) # Turns the csv file into a string that can be passed to the LLM\n",
    "\n",
    "param_dict = get_range_parameters(data, params, styles) # Generates the parameters for the vehicles\n",
    "verify_parameters(param_dict, styles)\n",
    "\n",
    "print(param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the parameters for verification\n",
    "vehParameters.showGaussianLLM(param_dict, [data['Parameter'][i] for i in range(len(data['Parameter']))], styles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the vehicle types for each student\n",
    "n_vtypes = 5 \n",
    "veh_style_per_student = []\n",
    "for i in range(len(location_time_list)):\n",
    "    veh_style_per_student.append(styles[i % len(styles)]) # Balacing the styles for the vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Random Trips to fill the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: If the desire is to generate alternative routes for the random trips, rand_trips must be set to randtrips.trips.xml, otherwise, the random_trips will be merged with the alternative routes for the LLM generated trips.\n",
    "rand_trips = None\n",
    "final_trips_file_name = \"finaltrips.rou.xml\"\n",
    "\n",
    "getRandomTrips(NET_PATH, ADDITONALS_PATH, \"passenger\", 10) # Generating random trips to randomtrips.rou.xml\n",
    "parseTripXML(param_dict, location_time_list, parkingAreas, departure_times, styles, veh_style_per_student, n_vtypes, steps_per_stop=10, rand_trips=rand_trips, out_file_name=final_trips_file_name) # Parsing to PATHGEN.trips.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Alternative Routes for each trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arguments to get alternative routes\n",
    "duaiterate_path = \"/usr/share/sumo/tools/assign/duaIterate.py\"\n",
    "def duaiterate_getArgs(net_path, trips_path, additional_path, iterations):\n",
    "    args = [\n",
    "        \"-n\", net_path,\n",
    "        \"-t\", trips_path,\n",
    "        \"--additional\", additional_path,\n",
    "        \"duarouter--additional-files\", additional_path,\n",
    "        \"-l\", str(iterations),\n",
    "    ]\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAltRoutes(net_path, trips_path, additional_path, iterations):\n",
    "    # Run the duarouter to find alternative routes\n",
    "    # Currently this only works for less than 10 iterations because of file naming\n",
    "    try:\n",
    "        subprocess.run(['python3', duaiterate_path] + duaiterate_getArgs(net_path, f'{FOLDER_NAME}/{trips_path}', additional_path, iterations), check=True)\n",
    "        file_name = trips_path.split('.')[0]\n",
    "\n",
    "        shutil.move(f'00{iterations-1}/{file_name}_00{iterations-1}.rou.alt.xml', f'{FOLDER_NAME}/{file_name}.rou.alt.xml')\n",
    "        for i in range(iterations):\n",
    "            if os.path.exists(f'00{i}'):\n",
    "                shutil.rmtree(f'00{i}')\n",
    "\n",
    "        shutil.move('dua.log', f'{FOLDER_NAME}/dua.log')\n",
    "        shutil.move('stdout.log', f'{FOLDER_NAME}/stdout.log')\n",
    "        os.remove('edgedata.add.xml')\n",
    "                \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the {final_trips_file_name}.rou.alt.xml file\n",
    "getAltRoutes(NET_PATH, final_trips_file_name, ADDITONALS_PATH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the trips and updating route files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no need to generate alternative router for the random trips, the following XML parser must be used to add them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_routes(alternative_routes, random_routes, output_file_name = 'merged.rou.alt.xml'):\n",
    "    # Merges two route files into one\n",
    "    \n",
    "    xml = '<routes xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"http://sumo.dlr.de/xsd/routes_file.xsd\">\\n'\n",
    "    xml += '\\n<!-- BEGIN - LLM Generated trips -->\\n'\n",
    "\n",
    "    with open(alternative_routes, 'r') as f:\n",
    "        start_read = False\n",
    "        for line in f:\n",
    "            test = line.strip()\n",
    "            if test.startswith('<vType'):\n",
    "                start_read = True\n",
    "            if start_read:\n",
    "                if line.startswith('</routes>'):\n",
    "                    break\n",
    "                xml += line\n",
    "\n",
    "    xml += '\\n\\n <!-- END - LLM Generated trips -->\\n\\n'\n",
    "    xml += '<!-- BEGIN - Random Trips -->\\n\\n'\n",
    "\n",
    "    with open(random_routes, 'r') as f:\n",
    "        start_read = False\n",
    "        for line in f:\n",
    "            test = line.strip()\n",
    "            if test.startswith('<vType'):\n",
    "                start_read = True\n",
    "            if start_read:\n",
    "                xml += line\n",
    "\n",
    "    with open(f'{FOLDER_NAME}/{output_file_name}', 'w') as f:\n",
    "        f.write(xml)\n",
    "    \n",
    "    return xml    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If alternative routes for random trips were ignored, the 'merged.rou.alt.xml' file will be created and should be used in osm.sumocfg\n",
    "output_file_name = 'merged.rou.alt.xml'\n",
    "if rand_trips == None:\n",
    "    if os.path.exists(f'{FOLDER_NAME}/{output_file_name}'):\n",
    "        os.remove(f'{FOLDER_NAME}/{output_file_name}')\n",
    "    \n",
    "    # If there are alternative routes, merge them\n",
    "    if os.path.exists(f'{FOLDER_NAME}/finaltrips.rou.alt.xml'):\n",
    "        merge_routes(f'{FOLDER_NAME}/finaltrips.rou.alt.xml', f'{FOLDER_NAME}/randtrips.rou.xml', output_file_name)\n",
    "\n",
    "    # If alternative routes were found not generated, we are going to use the original ones\n",
    "    else:\n",
    "        merge_routes(f'{FOLDER_NAME}/finaltrips.rou.xml', f'{FOLDER_NAME}/randtrips.rou.xml', output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing sumocfg to use the new route file\n",
    "add_xml_child(SUMOCFG_PATH, 'input', 'route-files', output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
