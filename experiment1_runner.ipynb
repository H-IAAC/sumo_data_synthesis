{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "import gzip\n",
    "\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    sys.path.append(os.path.join(os.environ['SUMO_HOME'], 'tools'))\n",
    "import sumolib\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import traci\n",
    "import traci.constants as tc\n",
    "\n",
    "# Add the \"scripts\" directory to sys.path\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "scripts_dir = os.path.abspath(os.path.join(current_dir, 'scripts'))\n",
    "sys.path.append(scripts_dir)\n",
    "import vehParameters\n",
    "import osmAPI as osm\n",
    "\n",
    "FOLDER_NAME = \"uah_map\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining paths and setting up osm.sumocfg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_xml_child(file_path, parent_tag, child_tag, child_value, replace=True):\n",
    "    \"\"\"\n",
    "    Adds a new child parameter inside a specified parent tag in the XML configuration file.\n",
    "    If the parent tag does not exist, it creates a new parent tag (<parameter>) with the child.\n",
    "    It also checks if the child element already exists to prevent duplicates.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the XML configuration file.\n",
    "        parent_tag (str): The parent tag under which to add the child (e.g., 'input').\n",
    "        child_tag (str): The child tag to add (e.g., 'additional-files').\n",
    "        child_value (str): The value to set for the new child tag.\n",
    "        replace (bool): If True, replaces the existing child tag with the new value.\n",
    "                        If False, adds another child value.\n",
    "    Returns:\n",
    "        bool: True if the addition was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Find the parent element by tag\n",
    "        parent_elem = root.find(parent_tag)\n",
    "        if parent_elem is None:\n",
    "            print(f\"Parent tag '{parent_tag}' not found. Creating new parent tag.\")\n",
    "            parent_elem = ET.Element(parent_tag)\n",
    "            root.append(parent_elem)\n",
    "            print(f\"Created new parent tag <{parent_tag}>.\")\n",
    "\n",
    "        # Check if the child element already exists inside the parent element\n",
    "        existing_child = parent_elem.find(child_tag)\n",
    "        if existing_child is not None: \n",
    "            \n",
    "            if existing_child.get('value') == child_value:\n",
    "                print(f\"Child <{child_tag}> with value '{child_value}' already exists. Skipping addition.\")\n",
    "                return False\n",
    "            else:\n",
    "                if replace:\n",
    "                    print(f\"Child <{child_tag}> already exists. Updating value to '{child_value}'.\")\n",
    "                    existing_child.set('value', child_value)\n",
    "                else:\n",
    "                    if child_value in existing_child.get('value').split(', '):\n",
    "                        print(f\"Child <{child_tag}> with value '{child_value}' already exists. Skipping addition.\")\n",
    "                        return False\n",
    "                    \n",
    "                    print(f\"Child <{child_tag}> already exists. Adding another child with value '{child_value}'.\")\n",
    "                    existing_child.set('value', f'{existing_child.get(\"value\")}, {child_value}')\n",
    "                \n",
    "                tree.write(file_path, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "                print(\"XML file updated successfully.\")\n",
    "                return True\n",
    "\n",
    "        # Create the new child element and set its value\n",
    "        new_child = ET.Element(child_tag)\n",
    "        new_child.set('value', child_value)\n",
    "        print(f\"Created <{child_tag}> with value '{child_value}'.\")\n",
    "\n",
    "        # Add the new child to the parent element\n",
    "        parent_elem.append(new_child)\n",
    "        print(f\"Added <{child_tag}> to <{parent_tag}>.\")\n",
    "\n",
    "        # Write the updated XML to the file\n",
    "        tree.write(file_path, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "        print(\"XML file updated successfully.\")\n",
    "        return True\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"XML Parsing error: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child <time-to-teleport> with value '100' already exists. Skipping addition.\n",
      "Child <lateral-resolution> with value '0.8' already exists. Skipping addition.\n",
      "Child <step-length> already exists. Updating value to '0.1'.\n",
      "XML file updated successfully.\n",
      "Child <end> already exists. Updating value to '864000.0'.\n",
      "XML file updated successfully.\n",
      "uah_map/park.add.xml does not exist. No using any parking areas.\n"
     ]
    }
   ],
   "source": [
    "NET_PATH = f'{FOLDER_NAME}/osm.net.xml'\n",
    "PA_PATH = f'{FOLDER_NAME}/park.add.xml'\n",
    "SUMOCFG_PATH = f'{FOLDER_NAME}/osm.sumocfg'\n",
    "PA_REROUTER_PATH = f'{FOLDER_NAME}/pa_rerouter.xml'\n",
    "\n",
    "# Setting up time to teleport as \n",
    "# -1 (never teleport): Vehicles will never teleport, but this could cause deadlock.\n",
    "# >0 (seconds): Vehicles will teleport after the specified time if they are not able to reach their destination.\n",
    "time_to_teleport = 100\n",
    "add_xml_child(SUMOCFG_PATH, 'processing', 'time-to-teleport', f'{time_to_teleport}')\n",
    "\n",
    "# Adding lateral resolution to use SubLane model\n",
    "lateral_resolution = 0.8\n",
    "add_xml_child(SUMOCFG_PATH, 'parameters', 'lateral-resolution', f'{lateral_resolution}')\n",
    "\n",
    "# Setting up the timestep (default is 1 second), this does not affect the simulation speed but the resolution of the simulation. A smaller timestep will result in a more accurate simulation\n",
    "step_length = 0.1\n",
    "add_xml_child(SUMOCFG_PATH, 'time', 'step-length', f'{step_length}')\n",
    "\n",
    "# Setting up the simulation duration. To simulate 24 hours, we set the end time to (3600 steps * 24 hours) / step_lenght.\n",
    "end_time = (3600 * 24) / step_length\n",
    "add_xml_child(SUMOCFG_PATH, 'time', 'end', f'{end_time}')\n",
    "\n",
    "if not os.path.exists(NET_PATH):\n",
    "    gz_path = f\"{FOLDER_NAME}/osm.net.xml.gz\"\n",
    "    if os.path.exists(gz_path):\n",
    "        with gzip.open(gz_path, 'rb') as f_in:\n",
    "            with open(NET_PATH, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        print(f\"Extracted {gz_path} to {NET_PATH}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{gz_path} does not exist.\")\n",
    "    \n",
    "net = sumolib.net.readNet(NET_PATH)\n",
    "\n",
    "if not os.path.exists(PA_PATH):\n",
    "    print(f\"{PA_PATH} does not exist. No using any parking areas.\")\n",
    "else:\n",
    "    parkingAreas = list(sumolib.output.parse(PA_PATH, \"parkingArea\"))\n",
    "    # Setting up additional files\n",
    "    add_xml_child(SUMOCFG_PATH, 'input', 'additional-files', \"park.add.xml, pa_rerouter.xml\")\n",
    "\n",
    "net_offset = net.getLocationOffset() # Necessary to convert from CARLA to SUMO coordinates if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_print():\n",
    "    sys.stdout.write(\"\\r\")  # Move the cursor to the beginning of the line\n",
    "    sys.stdout.write(\" \" * 50)  # Overwrite with spaces to clear the line\n",
    "    sys.stdout.write(\"\\r\")  # Move back to the beginning again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_parking_spot(lanes, parkingAreas):\n",
    "    # Example of parkingArea:\n",
    "    # <parkingArea id=\"pa-1046248579#0\" lane=\"-1046248579#0_0\" roadsideCapacity=\"94\" length=\"5.00\"/>\n",
    "    # Returns parkingArea id if there is a parking spot in the lane\n",
    "    lane_ids = [lane.getID() for lane in lanes]\n",
    "    for park in parkingAreas:\n",
    "        if park.lane in lane_ids:\n",
    "            return park.id\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClosestEdges(lat, lon, radius, maxEdges=10, convert_toXY=True):\n",
    "\n",
    "    # Gets the 10 closest edges to the given lat, lon\n",
    "    if convert_toXY:\n",
    "        x, y = net.convertLonLat2XY(lon, lat)\n",
    "    else:\n",
    "        x, y = lon, lat\n",
    "    edges = net.getNeighboringEdges(x, y, radius)\n",
    "    closestEdges = []\n",
    "    if (len(edges) > 0):\n",
    "        distanceAndEdges = sorted([(dist, edge) for edge, dist in edges], key=lambda x:x[0])\n",
    "\n",
    "        ## Checking if the edge found can be used by passenger car\n",
    "        for dist, edge in distanceAndEdges:\n",
    "            if edge.allows('passenger'):\n",
    "                closestEdges.append(edge)\n",
    "\n",
    "    if len(edges) == 0:\n",
    "        print(f'No edges found for {lat}, {lon}. Perhaps location is not inside the network or there are no viable roads inside the radius.')\n",
    "        return None\n",
    "    \n",
    "    return closestEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParkingSpot(lat, lon, radius, parkingAreas):\n",
    "    # Get the parking spot closest to the given lat, lon\n",
    "    # Used to set stops for the vehicles\n",
    "\n",
    "    edges = getClosestEdges(lat, lon, radius)\n",
    "    # Look for parking spots\n",
    "    for i in range(len(edges)):\n",
    "        parking_spot = has_parking_spot(edges[i].getLanes(), parkingAreas)\n",
    "        if parking_spot:\n",
    "            return parking_spot\n",
    "    print(f\"No parking spot found close to {lat}, {lon}. Perhaps decrease the radius?\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPath(location_time_list, parkingAreas, steps_per_stop, radius = 100, use_carla_routine=False):\n",
    "    # All that is needed to create the trip are the stops (parking areas) and the start and end edges.\n",
    "    # The duarouter is responsible for finding the path between the edges going through the stops.\n",
    "    # Here, we get the edges and stops that are going to be sent to LLAMA to create the trip.\n",
    "\n",
    "    # 'coordinates' is a list of tuples with the latitude and longitude of the points of interest, for example IC, FEEC, IC means that\n",
    "    # the vehicle will start from IC, stop at a parking lot close to FEEC, and then back to IC.\n",
    "    # The first and last coordinates should be edges and the others should be parking spots.\n",
    "    # `steps_per_stop` is the number of simulation steps that the vehicle will stay at each stop.\n",
    "\n",
    "    # Departure for 7 is 0, 8 is 100, 9 is 200 and so on\n",
    "    stop_durations = []\n",
    "    departures = list(location_time_list.keys())\n",
    "    stop_durations.append(-1) # Indicates this is an edge and not a parking spot\n",
    "\n",
    "    path = []\n",
    "    coords = [location_time_list[k]['coords'] for k in location_time_list.keys()]\n",
    "    \n",
    "    if use_carla_routine: \n",
    "        convert_toXY = False # No need to convert from lat, lon to XY\n",
    "        \n",
    "    home = getClosestEdges(*coords[0], radius, convert_toXY=convert_toXY)[0].getID()\n",
    "    path.append(home)\n",
    "        \n",
    "    for i in range(1, len(coords)-1):\n",
    "\n",
    "        stop_durations.append(steps_per_stop * (departures[i + 1] - departures[i]))\n",
    "        if use_carla_routine: # When using the carla routine, we don't have parking spots\n",
    "            ps = getClosestEdges(*coords[i], radius, convert_toXY=convert_toXY)[0].getID()\n",
    "        else:\n",
    "            ps = getParkingSpot(*coords[i], radius, parkingAreas)\n",
    "\n",
    "        if ps is not None:\n",
    "            path.append(ps)\n",
    "        else:\n",
    "            print(f\"Could not find parking spot for {coords[i]}\")\n",
    "            raise Exception(f\"Could not find parking spot for {coords[i]}\")\n",
    "\n",
    "    path.append(home)\n",
    "    stop_durations.append(-1)\n",
    "    \n",
    "    return path, stop_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(institutes):\n",
    "    cleaned_institutes = []\n",
    "    for institute in institutes:\n",
    "        # Remove parenthesis and everything after it\n",
    "        institute = re.sub(r'\\(.*', '', institute).strip()\n",
    "        \n",
    "        # Split by hyphen and take the longest slice\n",
    "        parts = institute.split('-')\n",
    "        longest_part = max(parts, key=len).strip()\n",
    "        # Split by '/' and add both parts to the cleaned_institutes list\n",
    "        if '/' in longest_part:\n",
    "            parts = longest_part.split('/')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                if part not in cleaned_institutes:\n",
    "                    cleaned_institutes.append(part)\n",
    "        else:\n",
    "            if longest_part not in cleaned_institutes:\n",
    "                cleaned_institutes.append(longest_part)\n",
    "        \n",
    "    return cleaned_institutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoords(trip, sulfixo, institutes, start_radius, step_radius, limit_radius, uni_center_lat, uni_center_lon, n_options = 3, restaurants = None):\n",
    "    # Returns a dictionary with the latitude and longitude of the locations of interest as well as the name of the location\n",
    "    # The suffix is the name of the state, city and neighborhood that will be added to the end of each location to improve the search\n",
    "    # 'start_radius' is the initial radius of the search, 'step_radius' is the amount that will be added to the radius if the location is not found and 'limit_radius' is the maximum radius that will be used. After that, the student will choose not to leave the place he is at.\n",
    "    # 'n_options' is the number of options of places we ideally want to find to choose from. This only applies while the limit_radius is not exceeded\n",
    "    \n",
    "    coords = {} # Coordinates for every place the student will visit\n",
    "    names = {}\n",
    "    importlib.reload(osm)\n",
    "    for i in range(len(trip)):\n",
    "        local = trip[f'{i + 7}']['location']\n",
    "        local_comp = local + \", \" + sulfixo\n",
    "\n",
    "        if local in coords.keys(): # If the location is already in the dictionary, use the coordinates from there\n",
    "            lat, lon = coords[local]\n",
    "            name = names[local]\n",
    "            continue\n",
    "        \n",
    "        if local == 'home': # If the location is home, use the home coordinates\n",
    "            coords['home'] = getHome()\n",
    "            names['home'] = 'home'\n",
    "            continue\n",
    "        \n",
    "        elif (local in institutes) or (restaurants and local in restaurants): # If the location is an institute, use the coordinates from the API\n",
    "                result = osm.geocode_address(local_comp)\n",
    "                \n",
    "                if not result:\n",
    "                    raise Exception(f\"Could not get coordinates for {local}, maybe its name is not correct\")\n",
    "\n",
    "                name = local\n",
    "                lat, lon = result[0]['latitude'], result[0]['longitude']\n",
    "                print(f\"\\033[1mFound {local} at {lat}, {lon}.\\033[0m\")\n",
    "\n",
    "        \n",
    "        else: # If the location is not an institute, we have to search for it in the OSM API\n",
    "            found = False\n",
    "            print(f\"Looking for {local}...\", end='', flush=True)\n",
    "\n",
    "            # Storing the previous location to use as a reference for the next search\n",
    "            names[local] = local\n",
    "            result = osm.find_nearby_building(uni_center_lat, uni_center_lon, local, radius=start_radius)\n",
    "            expanded = start_radius\n",
    "            if len(result) > 0: # Found at least one option\n",
    "                found = True\n",
    "\n",
    "            # If the location is not found or there are less optios than expected, expand the search radius\n",
    "            while len(result) == 0 or len(result) < n_options:\n",
    "                expanded += step_radius\n",
    "\n",
    "                if expanded > limit_radius:\n",
    "                    break\n",
    "\n",
    "                result = osm.find_nearby_building(uni_center_lat, uni_center_lon, local, radius=expanded)\n",
    "                if found == False and (len(result) > 0):\n",
    "                    found = True # Found at least one option, but will keep looking for more until the limit is reached\n",
    "\n",
    "            if found == False:\n",
    "                flush_print()\n",
    "                print(f\"Could not find {local} in a radius of {limit_radius} meters. The student will not leave the place he is currently at.\")\n",
    "\n",
    "            else:\n",
    "                random.shuffle(result) # Randomize the results to avoid always getting the absolute closest building\n",
    "                lat, lon = result[0]['latitude'], result[0]['longitude']\n",
    "                name = result[0]['name']\n",
    "                flush_print()\n",
    "                print(f\"Found {len(result)} options for {local}: {[x['name'] for x in result]}\")\n",
    "                print(f\"\\033[1m{local} picked: {result[0]['name']} at {lat}, {lon}.\\033[0m\")\n",
    "\n",
    "        \n",
    "        coords[f'{local}'] = (lat, lon)\n",
    "        names[f'{local}'] = name\n",
    "        \n",
    "    return coords, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordsToTrip(trip, coords, names = None):\n",
    "    location_time = {}\n",
    "    # The first location is always home\n",
    "    location_time[7] = {}\n",
    "    location_time[7]['location'] = 'home'\n",
    "    location_time[7]['coords'] = coords['home']\n",
    "    location_time[7]['name'] = 'home'\n",
    "    last = coords['home']\n",
    "    \n",
    "    for j in range(1, len(trip)):\n",
    "        location = trip[f'{j + 7}']['location']\n",
    "        location_coords = coords[location]\n",
    "        if names:\n",
    "            location_names = names[location]\n",
    "        else:\n",
    "            location_names = location\n",
    "\n",
    "        if location_coords != last:\n",
    "            # If the coordinates are the same as the last one, skip this location\n",
    "            location_time[j + 7] = {}\n",
    "            location_time[j + 7]['location'] = location\n",
    "            location_time[j + 7]['coords'] = location_coords\n",
    "            location_time[j + 7]['name'] = location_names\n",
    "            last = location_coords\n",
    "\n",
    "    return location_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathToXML(path, vehicleID, veh_type, departure_time, stop_durations, no_parking=False):\n",
    "    # Converts the path to the XML format that LLAMA understands\n",
    "    xml = f'<trip id=\"{vehicleID}\" type=\"{veh_type}\" depart=\"{departure_time}\" from=\"{path[0]}\" to=\"{path[-1]}\">\\n'\n",
    "    for i in range(1, len(path)-1):\n",
    "        if no_parking:\n",
    "            xml += f'\\t<stop edge=\"{path[i]}\" duration=\"{stop_durations[i]}\"/>\\n'\n",
    "        else:\n",
    "            xml += f'\\t<stop parkingArea=\"{path[i]}\" duration=\"{stop_durations[i]}\"/>\\n'\n",
    "\n",
    "    xml += '</trip>'\n",
    "    return xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_vtypes(routes_file, types_file, output_file):\n",
    "    # Parse the XML files\n",
    "    routes_tree = ET.parse(routes_file)\n",
    "    routes_root = routes_tree.getroot()\n",
    "    types_tree = ET.parse(types_file)\n",
    "    types_root = types_tree.getroot()\n",
    "    \n",
    "    # Extract existing vType IDs in routes_file\n",
    "    existing_vtypes = {vtype.get('id') for vtype in routes_root.findall('vType')}\n",
    "    \n",
    "    # Find vTypes in types_file that are not in routes_file\n",
    "    for vtype in types_root.findall(\".//vType\"):\n",
    "        if vtype.get('id') not in existing_vtypes:\n",
    "            routes_root.insert(0, vtype)\n",
    "    \n",
    "    # Write the updated routes file\n",
    "    routes_tree.write(output_file, encoding='utf-8', xml_declaration=True)\n",
    "    print(f\"Updated ROUTES_FILE saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will NOT USE CAR-FOLLOWING MODEL PARAMETERS because there are no other vehiles in the simulation. Details of the parameters are documented on the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = [\"normal\", \"aggressive\"]\n",
    "param_dict = {\n",
    "    'maxSpeed': {\n",
    "        'normal': 50 / 3.6, # m/s\n",
    "        'aggressive': 70 / 3.6,\n",
    "    },\n",
    "    'accel': { # Default value for SUMO passenger car is 2.6\n",
    "        'normal': 2.5,\n",
    "        'aggressive': 3.0,\n",
    "    },\n",
    "    'decel': { # Default value for SUMO is 4.5\n",
    "        'normal': 4.5,\n",
    "        'aggressive': 5.0,\n",
    "    },\n",
    "    'speedFactor': { # Slightly higher for aggressive drivers\n",
    "        'normal': 1.0,\n",
    "        'aggressive': 1.2,\n",
    "    },\n",
    "    'emergencyDecel': {\n",
    "        'normal': 9.0,\n",
    "        'aggressive': 10.0,\n",
    "    },\n",
    "    'vClass': {\n",
    "        'normal': 'passenger',\n",
    "        'aggressive': 'passenger',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<root>\\n<vType id=\"normal\" carFollowModel=\"EIDM\" laneChangeModel=\"SL2015\" maxSpeed=\\'13.88888888888889\\' accel=\\'2.5\\' decel=\\'4.5\\' speedFactor=\\'1.0\\' emergencyDecel=\\'9.0\\' vClass=\\'passenger\\' >\\n\\t<param key=\"device.rerouting.probability\" value=\"1.0\"/>\\n\\t<param key=\"device.rerouting.adaptation-steps\" value=\"18\"/>\\n\\t<param key=\"device.rerouting.adaptation-interval\" value=\"10\"/>\\n</vType>\\n<vType id=\"aggressive\" carFollowModel=\"EIDM\" laneChangeModel=\"SL2015\" maxSpeed=\\'19.444444444444443\\' accel=\\'3.0\\' decel=\\'5.0\\' speedFactor=\\'1.2\\' emergencyDecel=\\'10.0\\' vClass=\\'passenger\\' >\\n\\t<param key=\"device.rerouting.probability\" value=\"1.0\"/>\\n\\t<param key=\"device.rerouting.adaptation-steps\" value=\"18\"/>\\n\\t<param key=\"device.rerouting.adaptation-interval\" value=\"10\"/>\\n</vType>\\n</root>\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(vehParameters)\n",
    "# Parsing the vehicles to the XML format and writing to vTypesDistribution.xml\n",
    "vehParameters.parseVehicleTypesXML(param_dict, styles, FOLDER_NAME, car_follow_model=\"EIDM\", lc_model=\"SL2015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired edges need to be set. Their IDs are determined using **netedit uah_map/osm.net.xml** and looking for the desired edge in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated ROUTES_FILE saved as uah_map/experiment1/veh0_normal.rou.xml\n",
      "Updated ROUTES_FILE saved as uah_map/experiment1/veh1_aggressive.rou.xml\n"
     ]
    }
   ],
   "source": [
    "start_edge, end_edge = 28308066, -125136020 # Got edges from the net file\n",
    "list_of_ids = []\n",
    "\n",
    "os.makedirs(f\"{FOLDER_NAME}/experiment1\", exist_ok=True)\n",
    "for idx, style in enumerate(styles):\n",
    "    id = f'veh{idx}_{style}'\n",
    "    xml = pathToXML([start_edge, end_edge], f'veh{idx}_{style}', style, 0, [0, 0], no_parking=True) # Creates a test trip to check if the vehicle is working\n",
    "\n",
    "    # Write the XML to a file\n",
    "    exp1_trip_file = f\"{FOLDER_NAME}/experiment1/{id}.rou.xml\"\n",
    "    with open(exp1_trip_file, \"w\") as f:\n",
    "        f.write(f'<routes>\\n{xml}\\n</routes>')\n",
    "    add_missing_vtypes(exp1_trip_file, f\"{FOLDER_NAME}/vTypesDistribution.xml\", exp1_trip_file)\n",
    "\n",
    "    list_of_ids.append(id)\n",
    "\n",
    "# Writing the list of ids to a file\n",
    "with open(f\"{FOLDER_NAME}/experiment1/vehicle_ids.txt\", \"w\") as f:\n",
    "    for veh_id in list_of_ids:\n",
    "        f.write(f\"{veh_id}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the routes for the vehicles are saved to the experiment1 folder and we have to run the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_variables(vehIDs, personIDs, routine=None, delta_time=0.05, end_hours=24, useGui=False, convertGeo=True, freeze_traffic_lights=False):\n",
    "    \"\"\"\n",
    "    Function to get all variables from the simulation.\n",
    "    :param vehIDs: List of vehicle IDs to subscribe to.\n",
    "    :param personIDs: List of person IDs to subscribe to.\n",
    "    :param routine: Dictionary with the routine of the vehicles.\n",
    "    :param useGui: Boolean to use the GUI or not.\n",
    "    :param convertGeo: Boolean to convert the coordinates from sumo to lat/lon (does not work when using maps from CARLA).\n",
    "    :param freeze_traffic_lights: If true, traffic lights are green all the time.\n",
    "    :return: Dictionary with the variables.\n",
    "    \"\"\"\n",
    "\n",
    "    if useGui:\n",
    "        traci.start([\"sumo-gui\", \"-c\", f\"{FOLDER_NAME}/osm.sumocfg\"])\n",
    "    else:\n",
    "        traci.start([\"sumo\", \"-c\", f\"{FOLDER_NAME}/osm.sumocfg\"])\n",
    "    v_variables = {}\n",
    "    p_variables = {}\n",
    "\n",
    "    if end_hours != 0:\n",
    "        end_time = f'{end_hours * 60 * (60/delta_time)}' # 24 hours\n",
    "    else:\n",
    "        end_time = ''\n",
    "    \n",
    "    add_xml_child(f'{FOLDER_NAME}/osm.sumocfg', 'time', 'step-length', f'{delta_time}', replace=True)\n",
    "    add_xml_child(f'{FOLDER_NAME}/osm.sumocfg', 'time', 'end', end_time, replace=True)\n",
    "\n",
    "    # Get all traffic light IDs\n",
    "    if freeze_traffic_lights:\n",
    "        tls_ids = traci.trafficlight.getIDList()\n",
    "\n",
    "        # Set all traffic lights to constant green\n",
    "        for tls_id in tls_ids:\n",
    "            # Get logic info\n",
    "            logic = traci.trafficlight.getCompleteRedYellowGreenDefinition(tls_id)[0]\n",
    "\n",
    "            # Create a new green-only phase\n",
    "            green_state = 'G' * len(logic.phases[0].state)\n",
    "            green_phase = traci.trafficlight.Phase(duration=9999999, state=green_state)\n",
    "\n",
    "            # Replace the logic with only this green phase\n",
    "            new_logic = traci.trafficlight.Logic(\n",
    "                logic.programID, logic.type, logic.currentPhaseIndex, [green_phase]\n",
    "            )\n",
    "            traci.trafficlight.setCompleteRedYellowGreenDefinition(tls_id, new_logic)\n",
    "    \n",
    "    # To understand when a car has changed its destionation, we need to know it parked\n",
    "    if routine:\n",
    "        status = {}\n",
    "        for id in routine.keys():\n",
    "            status[id] = {}\n",
    "            status[id]['parked'] = False # True if the vehicle is parked\n",
    "            status[id]['count'] = 0 # Count of number of times a vehicle has parked\n",
    "            status[id]['stops'] = list(routine[id]['name']) # List of stops for the vehicle\n",
    "            status[id]['desc'] = f'<home-{status[id][\"stops\"][1]}>' # Description of the vehicle's status\n",
    "\n",
    "    time = 0\n",
    "    while traci.simulation.getMinExpectedNumber() > 0:\n",
    "\n",
    "        for veh_id in (set(traci.simulation.getDepartedIDList()) & set(vehIDs)): # Subscribe to vehicles that have just departed\n",
    "            print(f\"Vehicle {veh_id} has departed\")\n",
    "            traci.vehicle.subscribe(veh_id, [tc.VAR_POSITION, tc.VAR_SPEED, tc.VAR_ACCELERATION, tc.VAR_ANGLE])\n",
    "        \n",
    "        for veh_id in (set(traci.vehicle.getIDList()) & set(vehIDs)): # Checking status of vehicles that are already in the simulation\n",
    "            if routine:\n",
    "                is_parked = traci.vehicle.isStoppedParking(veh_id)\n",
    "                if not status[veh_id]['parked'] and is_parked:  # Vehicle was not parked and now is parked\n",
    "                    print(f\"Vehicle {veh_id} is parked.\")\n",
    "                    status[veh_id]['parked'] = True\n",
    "                    status[veh_id]['count'] += 1\n",
    "                    current_location = status[veh_id][\"stops\"][status[veh_id][\"count\"]]\n",
    "                    next_location = status[veh_id][\"stops\"][status[veh_id][\"count\"] + 1] if status[veh_id][\"count\"] + 1 < len(status[veh_id][\"stops\"]) else None\n",
    "                    status[veh_id]['desc'] = f'<{current_location}-{current_location}>'\n",
    "\n",
    "                elif status[veh_id]['parked'] and not is_parked:  # Vehicle was parked and now is not parked\n",
    "                    status[veh_id]['parked'] = False\n",
    "                    current_location = status[veh_id][\"stops\"][status[veh_id][\"count\"]]\n",
    "                    next_location = status[veh_id][\"stops\"][status[veh_id][\"count\"] + 1] if status[veh_id][\"count\"] + 1 < len(status[veh_id][\"stops\"]) else None\n",
    "                    status[veh_id]['desc'] = f'<{current_location}-{next_location}>'\n",
    "\n",
    "        for veh_id in (set(traci.simulation.getArrivedIDList()) & set(vehIDs)): # Vehicles that finished their route\n",
    "            # traci.vehicle.unsubscribe(veh_id)\n",
    "            if routine:\n",
    "                status[veh_id]['count'] += 1\n",
    "                current_location = status[veh_id][\"stops\"][status[veh_id][\"count\"]]\n",
    "                status[veh_id]['desc'] = f'<{current_location}-{current_location}>'\n",
    "\n",
    "        results = traci.vehicle.getAllSubscriptionResults().copy()\n",
    "\n",
    "        for veh_id in results.keys():\n",
    "            # Converting from x, y sumo coordinates to lat, lon\n",
    "            if convertGeo:\n",
    "                x, y = results[veh_id][tc.VAR_POSITION]\n",
    "                lon, lat = traci.simulation.convertGeo(x, y, fromGeo=False)\n",
    "                results[veh_id]['longitude'] = lon\n",
    "                results[veh_id]['latitude'] = lat\n",
    "                \n",
    "            if routine:\n",
    "                results[veh_id]['desc'] = status[veh_id]['desc']\n",
    "\n",
    "        v_variables[time] = results\n",
    "        \n",
    "        time += delta_time\n",
    "        traci.simulationStep()\n",
    "        \n",
    "    traci.close()\n",
    "    return v_variables, p_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(veh_variables, data_folder_name, vehIDs, delta_time, file_names_postfix = '', new_dir = False, type_ids_random = None, verify=True, type_ids_routine=None, use_desc=True, use_lat_lon=True, speed_threshold=6, acc_threshold=6, derivative_threshold=3):\n",
    "\n",
    "    if new_dir:\n",
    "        if not os.path.exists(f'{FOLDER_NAME}/{data_folder_name}'):\n",
    "            os.mkdir(f'{FOLDER_NAME}/{data_folder_name}')\n",
    "        else:\n",
    "            shutil.rmtree(f'{FOLDER_NAME}/{data_folder_name}')\n",
    "            os.mkdir(f'{FOLDER_NAME}/{data_folder_name}')\n",
    "\n",
    "    for timestep, data in veh_variables.items():\n",
    "        for vehID, vehData in data.items():\n",
    "\n",
    "            if use_lat_lon:\n",
    "                columns = 'timestamp,latitude,longitude,speed,speed_x,speed_y,acceleration,acceleration_x,acceleration_y,angle,acc_diff,gyroscope_z'\n",
    "            else:\n",
    "                columns = 'timestamp,x_pos,y_pos,speed,speed_x,speed_y,acc,acc_x,acc_y,angle,acc_diff,gyro_z'\n",
    "\n",
    "            path = f'{FOLDER_NAME}/{data_folder_name}/{vehID}{file_names_postfix}.csv'\n",
    "            nolabel_path = f'{FOLDER_NAME}/{data_folder_name}/{vehID}{file_names_postfix}_nolabel.csv'\n",
    "            if use_desc:\n",
    "                if not os.path.exists(path):\n",
    "\n",
    "                    with open(path, 'w') as f:\n",
    "                        f.write(f'{columns},desc\\n')\n",
    "            \n",
    "            if not os.path.exists(nolabel_path):\n",
    "                with open(nolabel_path, 'w') as f:\n",
    "                    f.write(f'{columns}\\n')\n",
    "                    \n",
    "            write_speed = vehData[SPEED]\n",
    "            write_angle = vehData[ANGLE]\n",
    "            write_acc = vehData[ACCELERATION]\n",
    "            write_x = vehData[POSITION][0]\n",
    "            write_y = vehData[POSITION][1]\n",
    "\n",
    "            if verify:\n",
    "                derivative_threshold\n",
    "                try: \n",
    "                    derivative_speed = (veh_variables[timestep][vehID][SPEED] - veh_variables[timestep-derivative_threshold][vehID][SPEED]) / derivative_threshold\n",
    "                    derivative_acceleration = (veh_variables[timestep][vehID][ACCELERATION] - veh_variables[timestep-derivative_threshold][vehID][ACCELERATION]) / derivative_threshold\n",
    "                except:\n",
    "                    derivative_speed = 0\n",
    "                    derivative_acceleration = 0\n",
    "                    \n",
    "                # Making verification to ensure there are no outliers\n",
    "                if derivative_speed > speed_threshold or derivative_speed < -speed_threshold:\n",
    "                    last_speed = veh_variables[timestep-delta_time][vehID][SPEED]\n",
    "                    print(f'Vehicle {vehID} at timestep {timestep} had a speed of {vehData[SPEED]}, it was changed to {last_speed}')\n",
    "                    veh_variables[timestep][vehID][SPEED] = last_speed\n",
    "                    write_speed = last_speed\n",
    "\n",
    "                if derivative_acceleration > acc_threshold or derivative_acceleration < -acc_threshold:\n",
    "                    last_acc = veh_variables[timestep - delta_time][vehID][ACCELERATION]\n",
    "                    print(f'Vehicle {vehID} at timestep {timestep} had an acceleration of {vehData[ACCELERATION]}, it was changed to {last_acc}')\n",
    "                    veh_variables[timestep][vehID][ACCELERATION] = last_acc\n",
    "                    write_acc = last_acc\n",
    "                \n",
    "                if vehData[ANGLE] < 0 or vehData[ANGLE] > 360:\n",
    "                    last_angle = veh_variables[timestep - delta_time][vehID][ANGLE]\n",
    "                    print(f'Vehicle {vehID} at timestep {timestep} had an angle of {vehData[ANGLE]}, it was changed to {last_angle}')\n",
    "                    veh_variables[timestep][vehID][ANGLE] = last_angle\n",
    "                    write_angle = last_angle\n",
    "\n",
    "            if write_speed < -100: # Invalid values\n",
    "                write_speed = 0\n",
    "                print(f'Vehicle {vehID} at timestep {timestep} had a INVALID speed of {vehData[SPEED]}, it was changed to 0')\n",
    "            if write_acc < -100 or write_acc > 100: # Invalid values\n",
    "                write_acc = 0\n",
    "                print(f'Vehicle {vehID} at timestep {timestep} had a INVALID acceleration of {vehData[ACCELERATION]}, it was changed to 0')\n",
    "\n",
    "            # Calculating the decomposed acceleration and speed\n",
    "            write_speed_x = write_speed * np.cos(np.radians(write_angle))\n",
    "            write_speed_y = write_speed * np.sin(np.radians(write_angle))\n",
    "            write_acc_x = write_acc * np.cos(np.radians(write_angle))\n",
    "            write_acc_y = write_acc * np.sin(np.radians(write_angle))\n",
    "            \n",
    "            try:\n",
    "                acc_diff = np.abs((veh_variables[timestep][vehID][ACCELERATION] -\n",
    "                                veh_variables[timestep - delta_time][vehID][ACCELERATION]) / delta_time)\n",
    "\n",
    "                current_angle = np.radians(veh_variables[timestep][vehID][ANGLE])\n",
    "                previous_angle = np.radians(veh_variables[timestep - delta_time][vehID][ANGLE])\n",
    "\n",
    "                # Proper angle wrapping to handle transitions like 359° -> 0°\n",
    "                angle_diff = np.arctan2(np.sin(current_angle - previous_angle),\n",
    "                                        np.cos(current_angle - previous_angle))\n",
    "\n",
    "                gyroscope_z = angle_diff / delta_time  # radians/second\n",
    "            except:\n",
    "                acc_diff = np.abs(write_acc)\n",
    "                gyroscope_z = 0.0\n",
    "\n",
    "            if use_lat_lon:\n",
    "                line = f'{timestep},{vehData[\"latitude\"]},{vehData[\"longitude\"]},{write_speed},{write_speed_x},{write_speed_y},{write_acc},{write_acc_x},{write_acc_y},{write_angle},{acc_diff},{gyroscope_z}'\n",
    "            else:\n",
    "                line = f'{timestep},{write_x},{write_y},{write_speed},{write_speed_x},{write_speed_y},{write_acc},{write_acc_x},{write_acc_y},{write_angle},{acc_diff},{gyroscope_z}'\n",
    "\n",
    "            if use_desc:\n",
    "                with open(path, 'a') as f:\n",
    "                    f.write(f'{line},{vehData[\"desc\"]}\\n')\n",
    "            \n",
    "            with open(nolabel_path, 'a') as f:\n",
    "                f.write(f'{line}\\n')\n",
    "        \n",
    "    # Creating the labels file\n",
    "    if use_desc:\n",
    "        with open(f'{FOLDER_NAME}/{data_folder_name}/labels.csv', 'w') as f:\n",
    "            f.write('ID,Type\\n')\n",
    "            found = False\n",
    "            for i in range(len(vehIDs)):\n",
    "            \n",
    "                if type_ids_random and not found:\n",
    "                    for key, value in type_ids_random.items():\n",
    "                        if vehIDs[i] in str(value):\n",
    "                            f.write(f'{vehIDs[i]},{key}\\n')\n",
    "                            found = True\n",
    "                            break\n",
    "                    \n",
    "                if type_ids_routine and not found:\n",
    "                    for key, value in type_ids_routine.items():\n",
    "                        if vehIDs[i] in str(value):\n",
    "                            f.write(f'{vehIDs[i]},{key}\\n')\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumoBinary = \"/usr/bin/sumo-gui\"\n",
    "sumoCmd = [sumoBinary, \"-c\", \"osm.sumocfg\"]\n",
    "\n",
    "# Code of each variable to subscribe:\n",
    "SPEED = 64\n",
    "POSITION = 66\n",
    "ACCELERATION = 114\n",
    "ANGLE = 67\n",
    "DEPATURE = 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_folder = \"data_experiment1_sumo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child <route-files> already exists. Updating value to 'experiment1/veh0_normal.rou.xml'.\n",
      "XML file updated successfully.\n",
      " Retrying in 1 seconds\n",
      "***Starting server on port 48833 ***\n",
      "Loading net-file from 'uah_map/osm.net.xml.gz' ... done (27ms).\n",
      "Loading route-files incrementally from 'uah_map/experiment1/veh0_normal.rou.xml'\n",
      "Loading done.\n",
      "Simulation version 1.23.1 started with time: 0.00.\n",
      "Child <step-length> already exists. Updating value to '0.01'.\n",
      "XML file updated successfully.\n",
      "Child <end> already exists. Updating value to ''.\n",
      "XML file updated successfully.\n",
      "Vehicle veh0_normal has departed\n",
      "Simulation ended at time: 486.40.\n",
      "Reason: TraCI requested termination.\n",
      "Performance:\n",
      " Duration: 1.64s\n",
      " TraCI-Duration: 1.52s\n",
      " Real time factor: 296.766\n",
      " UPS: 2967.053081\n",
      "Vehicles:\n",
      " Inserted: 1\n",
      " Running: 0\n",
      " Waiting: 0\n",
      "Statistics (avg of 1):\n",
      " RouteLength: 6664.31\n",
      " Speed: 13.70\n",
      " Duration: 486.30\n",
      " WaitingTime: 0.30\n",
      " TimeLoss: 6.39\n",
      " DepartDelay: 0.00\n",
      "DijkstraRouter answered 1 queries and explored 17.00 edges on average.\n",
      "DijkstraRouter spent 0.00s answering queries (0.00ms on average).\n",
      "Child <route-files> already exists. Updating value to 'experiment1/veh1_aggressive.rou.xml'.\n",
      "XML file updated successfully.\n",
      " Retrying in 1 seconds\n",
      "***Starting server on port 34155 ***\n",
      "Loading net-file from 'uah_map/osm.net.xml.gz' ... done (17ms).\n",
      "Loading route-files incrementally from 'uah_map/experiment1/veh1_aggressive.rou.xml'\n",
      "Loading done.\n",
      "Simulation version 1.23.1 started with time: 0.00.\n",
      "Child <step-length> with value '0.01' already exists. Skipping addition.\n",
      "Child <end> with value '' already exists. Skipping addition.\n",
      "Vehicle veh1_aggressive has departed\n",
      "Simulation ended at time: 348.43.\n",
      "Reason: TraCI requested termination.\n",
      "Performance:\n",
      " Duration: 10.75s\n",
      " TraCI-Duration: 9.91s\n",
      " Real time factor: 32.4181\n",
      " UPS: 3241.719390\n",
      "Vehicles:\n",
      " Inserted: 1\n",
      " Running: 0\n",
      " Waiting: 0\n",
      "Statistics (avg of 1):\n",
      " RouteLength: 6664.31\n",
      " Speed: 19.13\n",
      " Duration: 348.42\n",
      " WaitingTime: 0.25\n",
      " TimeLoss: 5.69\n",
      " DepartDelay: 0.00\n",
      "DijkstraRouter answered 1 queries and explored 17.00 edges on average.\n",
      "DijkstraRouter spent 0.00s answering queries (0.00ms on average).\n"
     ]
    }
   ],
   "source": [
    "experiment1_files = os.listdir(f'{FOLDER_NAME}/experiment1')\n",
    "delta_time = 0.01 # This delta time has to be the same as the one used in CARLA\n",
    "end_time = 0 # 0 means no end time, the simulation will run until all vehicles finish their route\n",
    "with open(f'{FOLDER_NAME}/experiment1/vehicle_ids.txt', 'r') as f:\n",
    "    vehIDs = f.read().splitlines()\n",
    "\n",
    "\n",
    "if os.path.exists(f'{FOLDER_NAME}/{output_data_folder}'):\n",
    "    shutil.rmtree(f'{FOLDER_NAME}/{output_data_folder}')\n",
    "os.makedirs(f'{FOLDER_NAME}/{output_data_folder}', exist_ok=True)\n",
    "\n",
    "for i in range(len(vehIDs)):\n",
    "\n",
    "    add_xml_child(f'{FOLDER_NAME}/osm.sumocfg', 'input', 'route-files', f'experiment1/{vehIDs[i]}.rou.xml', replace=True)\n",
    "    personIDs = []\n",
    "\n",
    "    try:\n",
    "        veh_variables, ped_variables = get_all_variables(vehIDs, personIDs, delta_time=delta_time, routine=None, end_hours=end_time, useGui=False, convertGeo=False, freeze_traffic_lights=True) # Running the simulation\n",
    "        save_data(veh_variables, output_data_folder, [vehIDs[i]], delta_time, new_dir=False, verify=True, use_lat_lon=False, use_desc=False)\n",
    "        \n",
    "    except KeyboardInterrupt as e:\n",
    "        traci.close() # Close the simulation if there is an error\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
